@c uncomment the following two lines for 'update every node' command
@c @node  cs
@c @chapter Constraint Satisfaction

@cindex Boltzmann Machines
@cindex Hopfield Networks
@cindex Interactive Activation and Competition
@cindex GRAIN Networks
@cindex Contrastive Hebbian Learning
@cindex Constraint Satisfaction
@cindex Phases, Plus and Minus

Constraint satisfaction is an emergent computational property of neural
networks that have recurrent connectivity, where activation states are
mutually influenced by each other, and settling over time leads to
states that satisfy the constraints built into the weights of the
network, and those that impinge through external inputs.

Constraint satisfaction can solve complicated computational problems
where the interdependencies among different possible solutions and
high-dimensional state spaces make searching or other techniques
computationally intractable.  The extent to which a network is
satisfying its constraints can be measured by a global energy or
"goodness" function.  Proofs regarding the stability of equilibrium
states of these networks and derivations of learning rules have been
made based on these energy functions.

In the PDP++ software, a collection of constraint satisfaction style
algorithms have been implemented under a common framework.  These
algorithms include the binary and continuous Hopfield style networks
@cite{Hopfield, 1982, 1984}, the closely related Boltzmann Machine
networks @cite{Ackley, Hinton and Sejnowski, 1985}, the interactive
activation and competition (IAC) algorithm @cite{McClelland and
Rumelhart, 1981}, and GRAIN networks @cite{Movellan and McClelland,
1994}.

In addition to recurrent activation propagation and settling over time,
these algorithms feature the important role that noise can play in
avoiding sub-optimal activation states.  The work with the GRAIN
algorithm extends the role of noise by showing that the network can
learn to settle into different distributions of activation states in a
probabilistic manner.  Thus, one can teach a network to go to one state
roughly 70 percent of the time, and another state roughly 30 percent of
the time.  These distributions of possible target states can be
specified by using a probability environment, which is described in a
subsequent section.

Also, learning takes place in these networks through a more local form
of learning rule than error backpropagation.  This learning rule,
developed for the Boltzmann machine, has been shown to work in a wide
variety of activation frameworks, including deterministic networks.
This rule can be described as a "contrastive Hebbian learning" (CHL)
function, since it involves the subtraction of two simple Hebbian terms
computed when the network is in two different "phases" of settling.

The two phases of settling required for learning are known as the
@i{minus} (negative) and @i{plus} (positive) phase.  The minus phase is
the state of the network when only inputs are presented to the network.
The plus phase is the state of the network when both inputs and desired
outputs are presented.  The CHL function states that the weights should
be updated in proportion to the difference of the coproduct of the
activations in the plus and minus phases:

@example
  cn->dwt = lrate * (ru->act_p * su->act_p - ru->act_m * su->act_m)
@end example

where @code{ru} is the receiving unit and @code{su} is the sending unit
across the connection @code{cn}, and @code{act_m} is the activation in
the minus phase, and @code{act_p} is the activation in the plus phase.

It turns out that in order to learn distributions of activation states,
one needs to collect many samples of activation states in a stochastic
network, and update the weights with the expected values of the
coproducts of the activations, but the general idea is the same.  This
learning rule can be shown to be minimizing the cross-entropy between
the distributions of the activations in the minus and plus phases, which
is the basis of the Boltzmann machine derivation of the learning rule.

The PDP++ implementation allows you to perform learning in both the
stochastic mode, and with deterministic networks using the same basic
code.  Also, there is support for @i{annealing} and @i{sharpening}
schedules, which adapt the noise and gain parameters (respectively) over
the settling trajectory.  Using these schedules can result in better
avoidance of sub-optimal activation states.

@menu
* cs-over::                     Overview of the Cs Implementation
* cs-con::                      Cs Connection Specifications
* cs-unit::                     Cs Unit Specifications
* cs-proc::                     Cs Processes
* cs-stats::                    Cs Statistics
* cs-defs::                     Cs Defaults
* cs-prob-env::                 The Probability Environment and Cs
* cs-impl::                     Cs Implementation Details
@end menu

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  cs-over, cs-con, cs, cs
@section Overview of the Cs Implementation

The Cs implementation defines a type of connection and connection spec
that is used by all flavors of Cs networks.  There is a basic CsUnit
which is also common to all algorithms, but each different type of
activation function defines its own version of the basic CsUnitSpec.
Thus, to switch activation functions, one needs only to point one's
units at a new unit spec type.

The new schedule process objects consist of three essential levels of
processing, starting at the trial level and moving down through settling
to the cycle, which implements one activation update of the network.
Thus, the @b{CsTrial} process loops over the plus and minus phases of
settling in the @b{CsSettle} process, which in turn iterates over cycles
of the @b{CsCycle} process, which updates the activations of the units
in the network.  There is an optional level of processing which involves
sampling over repeated settlings of the same pattern.  This repeated
sampling is used for learning to obtain reliable statistical estimates
of the probabilities of certain activation states, and is thus used when
learning to match a propability distribution over the output layer
(@pxref{cs-prob-env}).  This @b{CsSample} process loops over samples
of the @b{CsTrial} process.

There are several specialized statistic objects that compute the global
goodness or energy function of the network (@b{CsGoodStat}), and record
its probability of being in one of a number of desired activation states
(@b{CsDistStat}), and the extent to which the probabilities of these
states match their desired probabilities (@b{CsTIGstat},
@b{CsTargStat}).

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  cs-con, cs-unit, cs-over, cs
@section Cs Connection Specifications
@cindex Connections, Cs
@tindex CsCon
@tindex CsConSpec

The Cs connection type contains a computed change in weight term
@code{dwt}, a previous change in weight term @code{pdw}, and a change in
weight term that is used in aggregating weight change statistics over
time, @code{dwt_agg}.  The previous change in weight term enables
momentum-based learning to be performed.

The Cs connection specification type contains the following parameters:

@tindex CsConSpec
@table @code
@item float lrate
@vindex lrate of CsConSpec
Controls the rate of learning.  It simply multiplies the CHL
learning term.
@item float momentum
@vindex momentum of CsConSpec
The momentum, which includes a weighted average (weighted by the
@code{momentum} parameter) of prior weight changes in the current weight
change term.
@item float decay
@vindex decay of CsConSpec
The rate of weight decay, if a weight decay function is being
used.
@item  decay_fun
@vindex decay_fun of CsConSpec
There are two weight decay functions defined by default, but others can
be added.  These two are @code{Cs_Simple_WtDecay}, and
@code{Cs_WtElim_WtDecay}, which are just like their counterparts in the
Bp algorithm, to which you are referred for more details, see
@ref{bp-con}.
@end table

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  cs-unit, cs-proc, cs-con, cs
@section Cs Unit Specifications
@cindex Unit, Cs
@tindex CsUnit
@tindex CsUnitSpec

@vindex bias of CsUnit
@vindex da of CsUnit
@vindex act_m of CsUnit
@vindex act_p of CsUnit
The @b{CsUnit} is fairly simple.  As was described for backpropagation
(@pxref{bp-unit}) the bias weight is implemented as a connection object
on the unit.  It also keeps a record of the minus and plus phase
activation values, @code{act_m} and @code{act_p} (primarily for display
purposes), and the change in activation state for this unit, @code{da}.

All of the different flavors of constraint satisfaction algorithms
differ only in their activation function.  Thus, each one has a
different type of unit spec.  However, they all derive from a common
@b{CsUnitSpec}, which has parameters shared by all the different
algorithms.  This unit spec has the parameters for noise and gain, the
step size taken in updating activations, and schedules for adapting
noise and gain over time:

@table @code
@item CsConSpec_SPtr bias_spec
@vindex bias_spec of CsUnitSpec
Points the the connection spec that controls the learning of the
bias weight on the unit.
@item MinMaxRange real_range
@vindex real_range of CsUnitSpec
The actual range to allow units to be in. Typically, units are
kept within some tolerance of the absolute @code{act_range} values, in
order to prevent saturation of the computation of inverse-sigmoid
functions and other problems.
@item Random noise
@vindex noise of CsUnitSpec
These are the parameters of the noise to be added to the unit.
@code{GAUSSIAN} noise with zero mean is the standard form of noise to
use.  Noise is always added to the activations in an amount proportional
to the square-root of the step size (except in the BoltzUnitSpec, where
no noise is added).
@item float step
@vindex step of CsUnitSpec
The step size to take in updating activation values.  A smaller
step leads to smoother updating, but longer settling times.
@item float gain
@vindex gain of CsUnitSpec
The sharpness of the sigmoidal activation function, or 1 over
the temperature for the Boltzmann units.  A higher gain makes the units
act more like binary units, while a lower gain makes them act more
continuous and graded.
@item ClampType clamp_type
@vindex clamp_type of CsUnitSpec
This controls the way in which external inputs (from the environment)
are applied to the network.  @code{HARD_CLAMP} means that the activation
is exactly the @code{ext} value from the environment.
@code{HARD_FAST_CLAMP} is like hard clamp, but optimized so that all of
the inputs from clamped layers are computed once at the start of
settling, saving considerable computational overhead.  This should not
be used if the inputs are noisy, since this noise will not be included!
@code{SOFT_CLAMP} means that external inputs are added into the net
input to a unit, instead of forcing the activation value to take on the
external value.  @code{SOFT_THEN_HARD_CLAMP} performs soft clamping in
the minus phase, and then hard clamping in the plus phase.
@item float clamp_gain
@vindex clamp_gain of CsUnitSpec
When soft clamping, this parameter determines how strongly the external
input contributes to the unit net input.  It simply multiplies the value
in the @code{ext} field.
@item Random initial_act
@vindex initial_act of CsUnitSpec
Controls the random initialization of unit activations in the
@code{InitState} function.
@item bool use_annealing
@vindex use_annealing of CsUnitSpec
Controls whether an annealing schedule is used to adapt the
variance of the noise distribution over time (@code{noise_sched}).
@item Schedule noise_sched
@vindex noise_sched of CsUnitSpec
This schedule contains values which are multiplied times the @code{var}
parameter of the @code{noise} field to get an effective variance level.
The value from the schedule is the linear interpolation of the
@code{cycle} count from the settle process based on points listed in the
schedule.  Thus, each point in the schedule gives a variance multiplier
for a particular cycle count, and intermediate cycles yield interpolated
multiplier values.
@item bool use_sharp
@vindex use_sharp of CsUnitSpec
Controls whether a sharpening schedule is used to adapt the
gain parameter over time (@code{gain_sched}).
@item Schedule gain_sched
@vindex gain_sched of CsUnitSpec
This is a schedule for the gain multiplier.  The effective gain is the
@code{gain} parameter times the value from this schedule.  The schedule
works just like the @code{noise_sched} described above.
@end table

The basic @b{CsUnitSpec} uses the inverse-logistic activation function
developed by @cite{Movellan and McClelland, 1994}.  Thus, the change in
activation is a function of the difference between the actual net input,
and the inverse logistic of the current activation value.  This
formulation ends up being an exact solution to the objective function
used in their derivation.

@vindex time_avg on SigmoidUnitSpec
The @b{SigmoidUnitSpec} uses a simple sigmoidal function of the net
input, which is like the formulation of @cite{Hopfield, 1984}, and is
also the same as the RBp units described in @ref{rbp-unit}.  This type
also has the option with the @code{time_avg} parameter of computing time
averaging (i.e., as a function of the @code{step} parameter) on either
the @code{ACTIVATION} or the @code{NET_INPUT}, as was the case with the
RBp implementation.  As was described there the @code{NET_INPUT} option
allows units to settle faster.

@vindex temp of BoltzUnitSpec
The @b{BoltzUnitSpec} implements a binary activation function like that
used Boltzmann machine and the network of @cite{Hopfield, 1982}.  Here,
the unit takes on a 0 or 1 value probabilistically as a sigmoidal
function of the net input.  The gain of this sigmoid can also be
represented by its inverse, which is known as temperature, by analogy
with similar systems in statistical physics.  Thus, we have a
@code{temp} parameter which is used to update the gain parameter. Noise
is intrinsic to this function, and is not added in any other way.

@vindex rest of IACUnitSpec
@vindex decay of IACUnitSpec
@vindex use_send_thresh of IACUnitSpec
@vindex send_thresh of IACUnitSpec
The @b{IACUnitSpec} implements the interactive activation and
competition function.  This requires two new parameters, @code{rest} and
@code{decay}.  If the net input to the unit is positive, the activation
is increased by @code{net * (max - act)}, and if it is negative it is
decreased by @code{net * (act - min)}.  In either case, the activation
is also decayed towards the resting value by subtracting off a
@code{decay * (act - rest)} term.  IAC also has the option of only
sending activation to other units when it is over some threshold
(@code{send_thresh}).  Doing this requires a different way of computing
the net input to units, so it must be selected with the
@code{use_send_thresh} flag, and by setting the @code{update_mode} in
the @b{CsCycle} process to @code{SYNC_SENDER_BASED}.  Pressing
@i{ReInit} or @i{NewInit} at any level of process including and above
the @b{CsTrial} process will check for the consistency of these
settings, and prompt to change them.

The @b{LinearCsUnitSpec} computes activation as a simple linear function
of the net input.

@vindex threshold of ThreshLinCsUnitSpec
The @b{ThreshLinCsUnitSpec} computes activation as a threshold-linear
function of the net input, where net input below threshold gives an
activity of 0, and (net - threshold) above that.

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  cs-proc, cs-stats, cs-unit, cs
@section Cs Proceses
@cindex Process, Cs
@tindex CsCycle
@tindex CsSettle
@tindex CsTrial
@tindex CsSample

The core set of Cs processes consist of a @b{CsTrial} process that
performs the two phases of contrastive Hebbian learning (CHL), where
each phase of settling is controlled by a @b{CsSettle} process, which in
turn iterates over a number of individual @b{CsCycle} processing steps,
each of which updates the activation state of the network.  These
processes fit nicely within the standard settling and cycle processes
(@pxref{proc-levels}).

In addition, the @b{CsSample} process can be used to sample over trials
in order to obtain a better sampling of activation states for weight
updating, which is usually only necessary when trying to match a
probabalistic output distribution (@pxref{cs-prob-env}).  It is created
by default if using the @file{cs_prob_env.def} defaults file, but not
otherwise. 

The @b{CsTrial} process iterates over two loops of settle processing,
one for each phase.  It has the following variables:
@table @code
@item Counter phase_no
@vindex phase_no of CsTrial
The counter for this process, it goes from 1 to 2 for the two
different phases.
@item Phase phase
@vindex phase of CsTrial
The phase the process is in, which is just a more readable
version of the counter:  @code{MINUS_PHASE} and @code{PLUS_PHASE}.
@item StateInit trial_init
@vindex trial_init of CsTrial
Indicates what to do at the start of each trial process.
Typically, one wants to @code{INIT_STATE}, but it is also possible to
@code{DO_NOTHING} or @code{MODIFY_STATE}, which could be redefined by a
unit type to decay the activation state, for example (by default it just
does an init state).
@item bool no_plus_stats
@vindex no_plus_stats of CsTrial
This flag means that statistics will not be recorded in the plus phase.
This is useful because squared error, for example, is only meaningful in
the minus phase, since the correct answer is clamped in the plus phase.
@item bool no_plus_test
@vindex no_plus_test of CsTrial
This flag means that the plus phase will not be run if the epoch process
indicates that it is in @code{TEST} mode (i.e., no learning is taking
place).
@end table

@vindex between_phases of CsSettle
@vindex start_stats of CsSettle
@vindex deterministic of CsSettle
The @b{CsSettle} process iterates over cycles of settling (activation
updating).  Like the @code{trial_init} of the trial process, the
@code{between_phases} field of the settle process determines how the
network state will be initialized between phases.  Some people have
claimed that learning works better if you do not @code{INIT_STATE}
between phases (@cite{Movellan, 1990}).  However, the default is set to
initialize the state, so that settling starts from the same initial
conditions for both phases.

Also, the settle process allows the network to settle for some time
before collecting statistics for learning.  This time, determined by the
@code{start_stats} parameter, allows the network to get into a
stochastic equilibrium before measuring the activation states.  If using
a deterministic network, however, equilibrium is considered to simply be
the final state of the network after settling.  Setting the
@code{deterministic} flag will only update the weights based on the
final activation state.

The settle process will use the @code{time} field from a @b{TimeEvent}
as a @emph{duration} to settle on the event.  Note that this is a
non-standard use of this time field (@pxref{rbp-seq}).

@vindex update_mode of CsCycle
@vindex n_updates of CsCycle
The @b{CsCycle} process updates the activation state of the network.
This can be done in one of two ways --- either all of the units are
updated simultaneously (@code{SYNCHRONOUS} mode), or units are selected
at random and updated one at a time, which is @code{ASYNCHRONOUS} mode.
If the asynchronous mode is selected, one can perform multiple
asynchronous updates per cycle.  The number of units updated is
determined by the @code{n_updates} variable.  Note that the total number
of updates performed is the product of @code{n_updates} and the number
of cycles made during settling, so be sure to take that into account
when setting the values of either of these parameters.

A variation of the synchronous mode is the @code{SYNC_SENDER_BASED}
mode, which must be selected if IACUnitSpec's are being used, and the
@code{use_send_thresh} flag is set.  In this case, net input is computed
in a sender-based fashion, meaning that the net input for each unit must
first be initialized to zero, then accumulated.  In standard
receiver-based net input computation, the net input can be reset at the
point an individual unit's net input is computed, so it doesn't have to
be done for the entire network first.  This is the different between
SYNC_SENDER_BASED and SYNCHRONOUS.  Asynchronous updating is not
supported for sender-based updating.  When the @b{CsTrial} process is
@i{ReInit}'d or @i{NewInit}'d, it will automatically check for the
correct pairing of the use_send_thresh and update_mode flags, and inform
you if it needs to be changed.

@vindex sample of CsSample
The @b{CsSample} process has @code{sample} counter to keep track of the
number of samples run.  Set the @code{max} of this counter to 1 if you
are running a deterministic network, or are not doing learning on
probability distributions.  This process iterates over the trial
process, and only needs to be present when learning probabalistic output
distributions.

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  cs-stats, cs-defs, cs-proc, cs
@section Cs Statistics
@cindex Statistics, Cs

There are several statistics which are specific to the Cs package,
including one that compute the global "goodness" (aka energy) of the
network's activation state (@b{CsGoodStat}), another set of statistics
for measuring the probabilities of different activation states
(@b{CsDistStat, CsTIGstat, CsTargStat}), and a statistic that can be
used to control the length of settling based on the amount of activation
change (@b{CsMaxDa}).

@menu
* cs-stats-good::               The Goodness (Energy) Statistic
* cs-stats-dist::               Statistics for Measuring Probability Distributions
* cs-stats-maxda::              Measuring the Maximum Delta-Activation
@end menu

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  cs-stats-good, cs-stats-dist, cs-stats, cs-stats
@subsection The Goodness (Energy) Statistic
@tindex CsGoodStat
@cindex Harmony
@cindex Stress
@cindex Goodness

The @b{CsGoodStat} computes the overall goodness of the activation
state, which is composed of two terms, the @i{harmony} and @i{stress}.
Harmony reflects the extent to which the activations satisfy the
constraints imposed by the weights.  It is just a sum over all units of
the product of the activations times the weights:

@iftex
@tex
% html H = SUM_j SUM_i a_j w_ij a_i
$$   H = \sum_j \sum_i a_j w_{ij} a_i $$	
@end tex
@end iftex
@ifinfo
     H = SUM_j SUM_i a_j w_ij a_i
@end ifinfo

The stress term reflects the extent to which unit's activations are
"stressed" at their extreme values.  It is just the inverse sigmoidal
function of the unit activation values:

@iftex
@tex
% html S = SUM_j f^-1(a_j) 
$$   S = \sum_j f^{-1}(a_j) $$	
@end tex
@end iftex
@ifinfo
     S = SUM_j f^-1(a_j) 
@end ifinfo

The total goodness is just the harmony minus the stress. These values
are stored in the @code{hrmny}, @code{strss}, and @code{gdnss} stat
value members of the goodness stat.  Also, there is an option
(@code{netin_hrmny}) to use the net input to a unit in computing the
harmony term, since harmony is just the unit's activation times its net
input.  This should be used whenever it is safe to assume that the net
input reflects the current activation states (i.e., most of the time).
The example project in @file{demo/cs/figgr.proj.gz} shows how the
goodness function measures the quality of the constraint satisfaction
over time in a large-scale constraint satisfaction problem.

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  cs-stats-dist, cs-stats-maxda, cs-stats-good, cs-stats
@subsection Statistics for Measuring Probability Distributions
@tindex CsDistStat
@tindex CsTIGstat
@tindex CsTargStat
@cindex Distributions, Measuring
@cindex Total Information Gain

@vindex tolerance of CsDistStat
The @b{CsDistStat} is used to measure the percentage of time (i.e., the
probability) that the units in the network which have target patterns in
the environment spend in any of the possible target patterns.  This is
used when there are multiple possible target states defined for any
given event (see @ref{cs-prob-env}), which means that a simple
squared-error comparison against any one of these would be relatively
meaningless --- one wants to know how much time is spent in each of the
possible states.  The dist stat generates one column of data for each
possible target pattern, and each column represents the probability
(proportion of time) that the network's output units were within some
distance of the target pattern.  The tolerance of the distance measure
is set with the @code{tolerance} parameter, which is the absolute
distance between target and actual activation that will still result in
a zero distance measure. A network is considered to be "in" a particular
target state whenever its total distance measure is zero, so this
tolerance should be relatively generous (e.g., .5 so units have to be on
the right side of .5).

@vindex dist_stat of CsTIGstat
The @b{CsTIGstat} is essentially a way of aggregating the columns of
data produced by the @b{CsDistStat}.  It is automatically created by the
dist stat's @code{CreateAggregates} function (@pxref{proc-stat}) at the
level of the @b{CsSample} process (note that unlike other aggregators, it
is in the @code{final_stats} group of the sample process, and it feeds
off of the aggregator of the dist stat in the @code{loop_stats} of the
same process).  The TIG stat measures the total information gain (aka
cross-entropy) of the probability distribution of target states observed
in the network (as collected by the dist stat pointed to by the
@code{dist_stat} member), and the target probability distribution as
specified in the probability patterns themselves (@pxref{cs-prob-env}).
This measure is zero if the two distributions are identical, and it goes
up as the match gets worse.  It essentially provides a distance metric
over probability distributions.

The @b{CsTargStat}, like the TIG stat, provides a way of aggregating the
distribution information obtained by the dist stat.  This should be
created in the sample @code{final_stats} group (just like the TIG stat),
and its @code{dist_stat} pointer set to the aggregator of the dist stat
in the sample process @code{loop_stats}.  This stat simply records the
sum of each column of probability data, which provides a measure of how
often the network is settling into one of the target states, as opposed
to just flailing about in other random states.

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  cs-stats-maxda,  , cs-stats-dist, cs-stats
@subsection Measuring the Maximum Delta-Activation
@tindex CsMaxDa

The @b{CsMaxDa} statistic computes the maximum delta-activation (change
in activation) for any unit in the network.  This is used to stop
settling once the network has reached equilibrium.  The stopping
criterion for this statistic is the tolerance with which equilibrium is
measured.  It is created by default if the @code{deterministic} flag is
checked in the @b{CsSettle} process when it is created, which can be
done by using the @file{cs_det.def} defaults (det = deterministic).
This stat typically goes in the settle process @code{loop_stats}.


@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  cs-defs, cs-prob-env, cs-stats, cs
@section Cs Defaults
@cindex Defaults, Cs
@cindex Cs, Defaults

The following default files (@pxref{proj-defaults}) are available for
configuring different versions of the Cs objects:

@table @file
@item cs.def
This is the standard defaults file, which uses a SigmoidUnitSpec, and
the standard process heirarchy, assuming stochastic processing.
@item cs_det.def
This is for deterministic Cs networks, which means that only one sample
is made of activation states for computing weight changes at the end of
settling, and the CsMaxDa settling stat is created by default.
@item cs_prob_env.def
This configures the probabalistic output patterns version of Cs, meaning
that the CsSettle process is created, and the environment will create
probablistic events (@pxref{cs-prob-env}).
@end table

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  cs-prob-env, cs-impl, cs-defs, cs
@section The Probability Environment and Cs
@cindex Environment, Probability
@cindex Patterns, Probabilistic
@tindex ProbPattern
@tindex ProbPatternSpec_Group
@tindex ProbEventSpec

An environment can be specified where each event has multiple possible
target patterns, each of which has an associated probability of
occurring.  Thus, when an event is presented to the network, one out of a
set of possible target patterns is chosen according to their relative
probabilities.  These probabilistic distributions of target states can
actually be learned in a stochastic constraint satisfaction network.

@vindex prob of ProbPattern
Probabilities can be associated with different patterns by creating
@b{ProbPattern} objects instead of the usual @b{Pattern} ones.  The prob
pattern has a @code{prob} field, which contains its probability of
occurrence.

However, in order for these probabilities to be used in the presentation
of patterns, one needs to use a @b{ProbEventSpec}, which has special
code that chooses which pattern to present based on its probability.
Not all patterns in an event need to be probabilistic.  Indeed, the
usual setup is to have a deterministic input pattern, and then a set of
possible outputs that follow from this one input.  The determiniation of
which patterns are probabilistic and which are deterministic is made by
putting all of the mutually-exclusive probabilistic alternative patterns
in a @b{ProbPatternSpec_Group}. 

Thus, one needs to make a sub-group in the @code{patterns} group on the
@b{ProbEventSpec}, and this sub-group has to be of type
@b{ProbPatternSpec_Group}.  Then, regular @b{PatternSpec} objects, one
for each alternative target pattern, should be created in the sub group.
Make sure to set the @code{pattern_type} field of these pattern specs to
be @b{ProbPattern}, so that the patterns which are created in the event
will have probabilities associated with them.

When events are actually created from a prob event spec, one needs to
edit the patterns within the sub-group and assign each of them
probabilities that sum to 1 for all the patterns in the group.  Thus,
the network will be certain of choosing one of them to present.

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  cs-impl,  , cs-prob-env, cs
@section Cs Implementational Details

Note that the weight change operation in Cs is viewed as the process of
collecting statistics about the coproducts of activations across the
weights.  Thus, there is a new function at the level of the
@b{CsConSpec} called @code{Aggregate_dWt}, which increments the
@code{dwt_agg} value of the connection by the phase (+1.0 for plus
phase, -1.0 for the minus phase) times the coproduct of the activations.
This function is called repeatedly if learning is taking place after the
@code{start_stats} number of cycles has taken place. 

The standard @code{Compute_dWt} function is then called at the end of
the sample process, and it divides the aggregated weight change value by
a count of the number of times it was aggregated, so that the result is
an expected value measure.

Also, note that the type of momentum used in Cs corresponds to the
@code{BEFORE_LRATE} option of backpropagation (@pxref{bp-con}).

The following is a chart describing the flow of processing in the Cs
algorithm, starting with the epoch process, since higher levels do not
interact with the details of particular algorithms:

@example
@group
EpochProcess: @{
  Init: @{                              // at start of epoch
    environment->InitEvents();          // init events (if dynamic)
    event_list.Add() 0 to environment->EventCount(); // get list of events
    if(order == PERMUTE) event_list.Permute();       // permute if necessary
    GetCurEvent();                      // get pointer to current event
  @}
  Loop (sample): @{                      // loop over samples
    CsSample: @{                         // sample process (one event)
      Init: @{                          // at start of sample
        cur_event = epoch_proc->cur_event; // get cur event from epoch
      @}
      Loop (sample): @{                 // loop over samples of event
        CsTrial: @{                    // phase process (one phase)
          Init: @{                      // at start of phase
            phase = MINUS_PHASE;        // start in minus phase
            if(phase_init == INIT_STATE)  network->InitState();
            cur_event = epoch_proc->cur_event;  // get cur event from epoch
            cur_event->ApplyPatterns(network);  // apply patterns to network
          @}
          Loop (phase_no [0 to 1]): @{  // loop over phases 
            CsSettle: @{                // settle process (one settle)
              Init: @{                  // at start of settle
                if(CsPhase::phase == PLUS_PHASE) @{
                  network->InitState(); // init state (including ext input)
                  cur_event->ApplyPatterns(network);  // re-apply patterns
                  Targ_To_Ext();        // turn targets into external inputs
                @}
              @}
              Loop (cycle): @{          // loop over act update cycles
                CsCycle: @{             // cycle process (one cycle)
                  Loop (once): @{       // only process this once per cycle
                    Compute_SyncAct() or Compute_AsyncAct(); // see below
                    if(!deterministic and cycle > start_stats)
                      Aggregate_dWt();  // aggregate wt changes
                  @}
                @}
              @}
              Final: @{                 // at end of phase
                if(deterministic) Aggregate_dWt();  // do at end
                PostSettle();           // copy act to act_p or act_m
              @}
            @}
            phase = PLUS_PHASE;         // change to plus phase after minus
          @}
        @}
      @}
      Final: @{                         // at end of sample (done with event)
        network->Compute_dWt();         // compute wt changes based on aggs
      @}
    @}
    if(wt_update == ON_LINE or wt_update == SMALL_BATCH and trial.val % batch_n)
      network->UpdateWeights();         // update weights after sample if necc
    GetCurEvent();                      // get next event to present
  @}
  Final:                                // at end of epoch 
    if(wt_update == BATCH)  network->UpdateWeights();
@}
@end group
@end example

The activation computing functions are broken down as follows:

@example
@group
Compute_SyncAct(): @{           // compute synchronous activations
  network->InitDelta();         // initialize net-input terms
  network->Compute_Net();       // aggregate net inputs

  network->layers: @{           // loop over layers
    units->Compute_Act(CsSettle::cycle); // compute act from net
  @}                            // (cycle used for annealing, sharpening)
@}
@end group
@end example

@example
@group
Compute_AsyncAct(): @{          // compute asynchronous activations
  for(i=0...n_updates) @{       // do this n_updates times per cycle
    rnd_num = Random between 0 and CsSettle::n_units;  // pick a random unit
    network->layers: @{         // loop over layers
      if(layer contains rnd_num unit) @{ // find layer containing unit
        unit = layer->unit[rnd_num];    // get unit from layer
        unit->InitDelta();              // initialize net input terms
        unit->Compute_Net();            // aggregate net inputs
        unit->Compute_Act(CsSettle::cycle);  // compute act from net
      @}                        // (cycle used for annealing, sharpening)
    @}
  @}
@}
@end group
@end example


