@c uncomment the following two lines for 'update every node' command
@c @node  bp
@c @chapter Backpropagation

@cindex Backpropagation
@cindex Error Backpropagation

Backpropagation is perhaps the most commonly used neural network
learning algorithm.  Several different "flavors" of backpropagation have
been developed over the years, several of which have been implemented in
the PDP++ software, including the use of different error functions such
as cross-entropy, and recurrent backprop, from the simple recurrent
network to the Almeida-Pineda algorithm up to the real-time continuous
recurrent backprop.  The implementation allows the user to extend the
unit types to use different activation and error functions in a
straightforward manner.

Note that the simple recurrent networks (SRN, a.k.a. Elman networks) are
described in the feedforward backprop section, as they are more like
feedforward networks than the fully recurrent ones.

@menu
* bp-ff::                       Feedforward Backpropagation
* rbp::                         Recurrent Backpropagation
@end menu

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  bp-ff, rbp, bp, bp
@section Feedforward Backpropagation

@menu
* bp-over::                     Overview of the Bp Implementation
* bp-con::                      Bp Connection Specifications
* bp-unit::                     Bp Unit Specifications
* bp-proc::                     The Bp Trial Process
* bp-vari::                     Variations Available in Bp
* bp-srn::                      Simple Recurrent Networks in Bp
* bp-defs::                     Bp Defaults
* bp-impl::                     Bp Implementation Details
@end menu


@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  bp-over, bp-con, bp-ff, bp-ff
@subsection Overview of the Bp Implementation
@cindex Backpropagation, Implementation
@cindex Implementation, Backpropagation

The basic structure of the backpropagation algorithm is reviewed in the
tutorial (@pxref{tut-bp}).  In short, there are two phases, an
activation propagation phase, and an error backpropagation phase.  In
the simplest version of Bp, both of these phases are strictly
feed-forward and feed-back, and are computed sequentially
layer-by-layer.  Thus, the implementation assumes that the layers are
organized sequentially in the order that activation flows.

In the recurrent versions, both the activation and the error propagation
are computed in two steps so that each unit is effectively being updated
simultaneously with the other units.  This is done in the activation
phase by first computing the net input to each unit based on the other
units current activation values, and then updating the activation values
based on this net input.  Similarly, in the error phase, first the
derivative of the error with respect to the activation (dEdA) of each
unit is computed based on current dEdNet values, and then the dEdNet
values are updated based on the new dEdNet.

To implement a new algorithm like Bp in PDP++, one creates new class
types that derive from the basic object types that make up a network
(@pxref{net}), and scheduling processes (@pxref{proc}).  These new
classes inherit all the functionality from the basic types, and specify
the details appropriate for a particular algorithm.  There are two ways
in which this specification happens---overloading (replacing) existing
functions, and adding new ones (@pxref{obj-basics-obj}).

The new classes defined in the basic Bp implementation include:
@b{BpConSpec, BpCon, BpCon_Group, BpUnit, BpUnitSpec, BpTrial}, the
role of which should be clear from their names.  In addition, we have
added a @b{CE_Stat} that computes the cross-entropy error statistic,
much in the same way @b{SE_Stat} does (@pxref{proc-stats-se}).

Bias weights in PDP++ are implemented by adding a @b{BpCon} object
to the @b{BpUnit} directly, and not by trying to allocate some kind of
self projection or some other scheme like that.  In addition, the
@b{BpUnitSpec} has a pointer to a @b{BpConSpec} to control the updating
etc of the bias weight.  Thus, while some code was written to support
the special bias weights on units, it amounts to simply calling the
appropriate function on the @b{BpConSpec}.

The processing hierarchy for feed-forward Bp requires only a specialized
Trial process: @b{BpTrial}, which runs both the feed-forward
activation updating and error backpropagation phases.  

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  bp-con, bp-unit, bp-over, bp-ff
@subsection Bp Connection Specifications
@cindex Connections, Backpropagation
@tindex BpCon
@tindex BpConSpec

In addition to the weight itself, the connection type in Bp,
@b{BpCon}, has two additional variables:

@table @code
@item float dwt
@vindex dwt of BpCon
The most recently computed change in the weight term.  It is
computed in the @code{UpdateWeights} function.
@item float dEdW
@vindex dEdW of BpCon
The accumulating derivative of the error with respect to the
weights.  It is computed in the @code{Compute_dWt} function.  It will
accumulate until the @code{UpdateWeights} function is called, which will
either be on a trial-by-trial or epoch-wise (batch mode) basis.
@end table

The connection specifications control the behavior and updating of
connections (@pxref{net-con}).  Thus, in Bp, this is where you will
find thinks like the learning rate and momentum parameters.  A detailed
description of the parameters is given below:

@table @code
@item float lrate
@vindex lrate of BpConSpec
The learning rate parameter.  It controls how fast the weights
are updated along the computed error gradient.  It should generally be
less than 1 and harder problems will require smaller learning rates.
@item float momentum
@vindex momentum of BpConSpec
The momentum parameter determines how much of the previous weight change
will be retained in the present weight change computation.  Thus,
weight changes can build up momentum over time if they all head in the
same direction, which can speed up learning.  Typical values are from .5
to .9, with anything much lower than .5 making little difference.
@item MomentumType momentum_type
@vindex momentum_type of BpConSpec
There are a couple of different ways of thinking about how momentum
should be applied, and this variable controls which one is used.
According to @code{AFTER_LRATE}, momentum is added to the weight
change @emph{after} the learning rate has been applied:
@example
  cn->dwt = lrate * cn->dEdW + momentum * cn->dwt;
  cn->wt += cn->dwt;
@end example
This was used in the original pdp software.  The @code{BEFORE_LRATE}
model holds that momentum is something to be applied to the gradient
computation itself, not to the actual weight changes made.  Thus,
momentum is computed @emph{before} the learning rate is applied to the
weight gradient:
@example
  cn->dwt = cn->dEdW + momentum * cn->dwt;
  cn->wt += lrate * cn->dwt;
@end example
Finally, both of the previous forms of momentum introduce a learning
rate confound since higher momentum values result in larger effective
weight changes when the previous weight change points in the same
direction as the current one.  This is controlled for in the
@code{NORMALIZED} momentum update, which normalizes the total
contribution of the previous and current weight changes (it also uses
the @code{BEFORE_LRATE} model of when momentum should be applied):
@example
  cn->dwt = (1.0 - momentum) * cn->dEdW + momentum * cn->dwt;
  cn->wt += lrate * cn->dwt;
@end example
Note that normalized actually uses a variable called @code{momentum_c}
which is pre-computed to be 1.0 - momentum, so that this extra
computation is not incurred needlessly during actual weight updates.
@item float decay
@vindex decay of BpConSpec
Controls the magnitude of weight decay, if any.  If the
corresponding @code{decay_fun} is @code{NULL} weight decay is not
performed.  However, if it is set, then the weight decay will be scaled
by this parameter.  Note that weight decay is applied @emph{before}
either momentum or the learning rate is applied, so that its effects are
relatively invariant with respect to manipulations of these other
parameters.
@item  decay_fun
@vindex decay_fun of BpConSpec
The decay function to be used in computing weight decay.  This is a
pointer to a function, which means that the user can add additional
decay functions as they wish.  However, the default ones are
@code{Bp_Simple_WtDecay}, which simply subtracts a fraction of the
current weight value, and @code{Bp_WtElim_WtDecay}, which uses the
"weight elimination" procedure of @cite{Weigand, Rumelhart, and
Huberman, 1991}.  This procedure allows large weights to avoid a strong
decay pressure, but small weights are encouraged to be eliminated:
@example
  float denom = 1.0 + (cn->wt * cn->wt);	
  cn->dEdW -= spec->decay * ((2 * cn->wt) / (denom * denom);
@end example
The ratio of the weight to the @code{denom} value is roughly
proportional to the weight itself for small weights, and is constant for
weights larger than 1.
@end table


@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  bp-unit, bp-proc, bp-con, bp-ff
@subsection Bp Unit Specifications
@cindex Units, Backpropagation
@tindex BpUnit
@tindex BpUnitSpec

The unit in Bp contains a bias weight and the various derivative terms
that are accumulated during the backpropagation phase:

@table @code
@item BpCon bias
@vindex bias of BpUnit
Contains the bias weight and its associated derivative and weight
change values.  The bias weight is controlled by the @code{bias_spec} on
the @b{BpUnitSpec}.
@item float err
@vindex err of BpUnit
Contains the actual error or cost associated with the unit.  It is
a function of the difference between the activation and the target
value, so it only shows up for those units that have target activation
values.  It is not to be confused with the derivative of the activation
with respect to the error, which is @code{dEdA}.
@item float dEdA
@vindex dEdA of BpUnit
The derivative of the error with respect to the activation of
the unit.  For output units using the squared-error function, it is
simply @code{(targ - act)}.  For hidden units, it is the accumulation of
the backpropagated @code{dEdNet} values times the intervening weights
from the units to which the unit sends activation.
@item float dEdNet
@vindex dEdNet of BpUnit
The derivative of the error with respect to the net input of the
unit.  It is simply the @code{dEdA} times the derivative of the
activation function, which is @code{act * (1 - act)} for standard
sigmoidal units.
@end table


The unit specifications for Bp control what kind of error function is
being used, the parameters of the activation function, and the functions
on the spec orchestrate the computation of the activation and error
backpropagation phases:

@table @code
@item SigmoidSpec sig
@vindex sig of BpUnitSpec
These are the parameters of the sigmoidal activation function.  The
actual range of this activations are determined by the @code{act_range}
parameters, and the @code{sig} parameters determine the gain and any
fixed offset of the function (the offset is like a fixed bias term).
@item float err_tol
@vindex err_tol of BpUnitSpec
The error tolerance allows activation values that are sufficiently close
to the target activation to be treated as though they were equal to the
target value.  Reasonable values of this parameter are from .02 to .1,
and its use prevents the large accumulation of weight values that
happens when the unit keeps trying to get closer and closer to an
activation of 1 (for example), which is impossible.
@item BpConSpec_SPtr bias_spec
@vindex bias_spec of BpUnitSpec
A pointer to a @b{BpConSpec} that controls the updating of
the unit's bias weight.  Typically, this points to the same
@b{BpConSpec} that updates the rest of the weights in the network,
but it is possible to have special @b{BpConSpec's} that do different
things to the bias weights, like initialize them to moderate negative
values, for example.
@item  err_fun
@vindex err_fun of BpUnitSpec
A pointer to the error function to use in computing error for
output units that have target values.  The function computes both
@code{err} and @code{dEdA} values (the former typically being the square
of the latter).  While the user can define additional error functions,
the two that come with the standard distribution are
@code{Bp_Squared_Error} and @code{Bp_CrossEnt_Error}, which compute the
squared error and cross-entropy error functions, respectively.
@end table

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  bp-proc, bp-vari, bp-unit, bp-ff
@subsection The Bp Trial Process
@cindex Process, Backpropagation Trial
@tindex BpTrial

The @b{BpTrial} process is the only Bp-specific process type needed
to perform simple feed-forward backprop.  The @code{Loop} function of
this process simply propagates activation forwards through the network,
and then propagates the error backwards.  This assumes that the layers
are ordered sequentially in a feed-forward manner.  Note that the
process does not actually "loop" over anything, so it has no counter.
See @ref{proc-levels-trial} for more information on the trial process
type. 

The following functions are defined on the trial process, each of which
performs one step of the backpropagation computations:

@table @code
@item Compute_Act()
@findex Compute_Act on BpTrial
Goes layer-by-layer and computes the net input and the activation of the
units in the layer.
@item Compute_Error()
@findex Compute_Error on BpTrial
Computes the error on the output units, which is only done during
testing, and not training.
@item Compute_dEdA_dEdNet()
@findex Compute_dEdA_dEdNet on BpTrial
Computes the derivative of the error with respect to the activation and
then with respect to the net inputs.  This goes in reverse order
through the layers of the network.
@item Compute_dWt()
@findex Compute_dWt on BpTrial
Computes the dEdW for all the weights in the network.
@end table


@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  bp-vari, bp-srn, bp-proc, bp-ff
@subsection Variations Available in Bp

There are several different @b{BpUnitSpec} and @b{BpConSpec} types
available that perform variations on the generic backpropagation
algorithm.

@tindex LinearBpUnitSpec
@b{LinearBpUnitSpec} implements a linear activation function

@tindex ThreshLinBpUnitSpec
@vindex threshold of ThreshLinBpUnitSpec
@b{ThreshLinBpUnitSpec} implements a threshold linear activation
function with the threshold set by the parameter @code{threshold}.
Activation is zero when net is below threshold, net-threshold above
that.

@tindex NoisyBpUnitSpec
@vindex noise of NoisyBpUnitSpec
@b{NoisyBpUnitSpec} adds noise to the activations of units.  The noise
is specified by the @code{noise} member.

@tindex StochasticBpUnitSpec
@b{StochasticBpUnitSpec} computes a binary activation, with the
probability of being active a sigmoidal function of the net input (e.g.,
like a Boltzmann Machine unit).

@tindex RBFBpUnitSpec
@vindex var of RBFBpUnitSpec
@b{RBFBpUnitSpec} computes activation as a Gaussian function of the
distance between the weights and the activations.  The variance of the
Gaussian is spherical (the same for all weights), and is given by the
parameter @code{var}.

@tindex BumpBpUnitSpec
@vindex mean of BumpBpUnitSpec
@vindex std_dev of BumpBpUnitSpec
@b{BumpBpUnitSpec} computes activation as a Gaussian function of the
standard dot-product net input (not the distance, as in the RBF).  The
mean of the effectively uni-dimensional Gaussian is specified by the
@code{mean} parameter, with a standard deviation of @code{std_dev}.

@tindex ExpBpUnitSpec
@b{ExpBpUnitSpec} computes activation as an exponential function of the
net input (e^net).  This is useful for implementing SoftMax units, among
other things.

@tindex SoftMaxBpUnitSpec
@b{SoftMaxBpUnitSpec} takes one-to-one input from a corresponding
exponential unit, and another input from a LinearBpUnitSpec unit that
computes the sum over all the exponential units, and computes the
division between these two.  This results in a SoftMax unit.  Note that
the LinearBpUnitSpec must have fixed weights all of value 1, and that
the SoftMaxUnit's must have the one-to-one projection from exp units
first, followed by the projection from the sum units.  See
@file{demo/bp_misc/bp_softmax.proj.gz} for a demonstration of how to
configure a SoftMax network.

@tindex HebbBpConSpec
@b{HebbBpConSpec} computes very simple Hebbian learning instead of
backpropagation.  It is useful for making comparisons between delta-rule
and Hebbian leanring.  The rule is simply @code{dwt = ru->act *
su->act}, where @code{ru->act} is the target value if present.

@tindex ErrScaleBpConSpec
@vindex err_scale of ErrScaleBpConSpec
@b{ErrScaleBpConSpec} scales the error sent back to the sending units by
the factor @code{err_scale}.  This can be used in cases where there are
multiple output layers, some of which are not supposed to influence
learning in the hidden layer, for example.

@tindex DeltaBarDeltaBpConSpec
@tindex DeltaBarDeltaBpCon
@vindex lrate_incr of DeltaBarDeltaBpConSpec
@vindex lrate_decr of DeltaBarDeltaBpConSpec
@b{DeltaBarDeltaBpConSpec} implements the delta-bar-delta learning rate
adaptation scheme @cite{Jacobs, 1988}.  It should only be used in batch
mode weight updating.  The connection type must be
@b{DeltaBarDeltaBpCon}, which contains a connection-wise learning rate
parameter.  This learning rate is additively incremented by
@code{lrate_incr} when the sign of the current and previous weight
changes are in agreement, and decrements it multiplicatively by
@code{lrate_decr} when they are not.  The demo project
@file{demo/bp_misc/bp_ft_dbd.proj.gz} provides an example of how to set
up delta-bar-delta learning.  The defaults file @file{bp_dbd.def}
provides a set of defaults that make delta-bar-delta connections by
default.

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  bp-srn, bp-defs, bp-vari, bp-ff
@subsection Simple Recurrent Networks in Bp
@cindex Simple Recurrent Networks

@tindex BpWizard
@findex SRNContext on BpWizard
Simple recurrent networks (SRN) @cite{Elman, 1988} involve the use of
a special set of context units which copy their values from the hidden
units, and from which the hidden units receive inputs.  Thus, it
provides a simple form of recurrence that can be used to train
networks to perform sequential tasks over time.  @b{New for 3.0:} the
@b{BpWizard} has a @code{Network/SRNContext} function that will
automatically build an SRN context layer as described below.

The implementation of SRN's in PDP++ uses a special version of the
@b{BpUnitSpec} called the @b{BpContextSpec}.  This spec overloads
the activation function to simply copy from a corresponding hidden unit.
The correspondence between hidden and context units is established by
creating a single one-to-one projection into the context units from the
hidden units.  The context units look for the sending unit on the other
side of their first connection in their first connection group for the
activation to copy.  This kind of connection should be created with a
@b{OneToOnePrjnSpec} (@pxref{net-prjn-spec}).

@strong{Important:} The context units should be in a layer that
@emph{follows} the hidden units they copy from.  This is because the
context units should provide input to the hidden units before copying
their activation values.  This means that the hidden units should update
themselves first.

The context units do not have to simply copy the activations directly
from the hidden units.  Instead, they can perform a time-averaging of
information through the use of an updating equation as described below.
The parameters of the context spec are as follows:

@tindex BpContextSpec
@table @code
@item float hysteresis
@vindex hysteresis of BpContextSpec
Controls the rate at which information is accumulated by the context
units.  A larger hysteresis value makes the context units more sluggish
and resistant to change; a smaller value makes them incorporate
information more quickly, but hold onto it for a shorter period of time:
@example
  u->act = (1.0 - hysteresis) * hu->act + hysteresis * u->act;
@end example
@item Random initial_act
@vindex initial_act of BpContextSpec
These parameters determine the initial activation of the context units.
Unlike other units in a standard Bp network, the initial state of the
context units is actually important since it provides the initial input
to the hidden units from the context.
@end table

Note that the SRN typically requires a sequence model of the
environment, which means using the sequence processes
(@pxref{proc-special-seq}).  Typically, the activations are initialized
at the start of a sequence (including the context units), and then a
sequence of related events are presented to the network, which can then
build up a context representation over time since the activations are
not initialized between each event trial.

The defaults file @file{bp_seq.def} contains a set of defaults for Bp
that will create sequence processes by default (@pxref{bp-defs}).

The demo project @file{demo/bp_srn/srn_fsa.proj.gz} is an example of a
SRN network that uses the sequence processes.  It also illustrates the
use of a @b{ScriptEnv} where a CSS script is used to dynamically
create new events that are generated at random from a finite state
automaton. 


@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  bp-defs, bp-impl, bp-srn, bp-ff
@subsection Bp Defaults
@cindex Defaults, Bp
@cindex Bp, Defaults

The following default files (@pxref{proj-defaults}) are available for
configuring different versions of the Bp objects:

@table @file
@item bp.def
This is the standard defaults file, for standard feedforward
backpropagation with sigmoidal units.
@item bp_seq.def
This is for doing simple recurrent networks (@pxref{bp-srn}) in Bp.  It
creates SequenceEpoch and SequenceProc processes instead of a standard
EpochProcess.
@item bp_dbd.def
This creates delta-bar-delta connections by default (including bias
connections).
@end table

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  bp-impl,  , bp-defs, bp-ff
@subsection Bp Implementation Details

Many of the relevant details are discussed above in the context of the
descriptions of the basic Bp classes.  This section provides a little
more detail that might be useful to someone who wanted to define their
own versions of Bp classes, for example.

Support for the activation updating phase of Bp is present in the basic
structure of the PDP++ @ref{net-unit} and @ref{net-con} types,
specifically in the @code{Compute_Net} and @code{Compute_Act} functions.
We overload @code{Compute_Act} to implement the sigmoidal activation
function.

The error backpropagation phase is implemented with three new functions
at both the unit and connection level.  The unit spec functions are:

@table @code
@item Compute_dEdA(BpUnit* u)
@findex Compute_dEdA on BpUnitSpec
Computes the derivative of the error with respect to the
activation.  If the unit is an output unit (i.e., it has the
@code{ext_flag} @code{TARG} set), then it just calls the error function
to get the difference between the target and actual output activation.
If it is not an output unit, then it iterates through the sending
connection groups (i.e., through the connections to units that this one
sends activation to), and accumulates its @code{dEdA} as a function of
the connection weight times the other unit's @code{dEdNet}.  This is done
by calling the function @code{Compute_dEdA} on the sending connection
groups, which calls this function on the @b{BpConSpec}, which is
described below.
@item Compute_dEdNet(BpUnit* u)
@findex Compute_dEdNet on BpUnitSpec
Simply applies the derivative of the activation function to the
already-computed @code{dEdA} to get the derivative with respect to the
net input.
@item Compute_Error(BpUnit* u)
@findex Compute_Error on BpUnitSpec
This function is not used in the standard training mode of Bp, but is
defined so that the error can be computed when a network is being
tested, but not trained.
@item Compute_dWt(Unit* u)
@findex Compute_dWt on BpUnitSpec
Computes the derivative of the error with respect to the weight
(@code{dEdW}) for all of the unit's connections.  This is a function of
the @code{dEdNet} of the unit, and the sending unit's activation.  This
function is defined as part of the standard @b{UnitSpec} interface,
and it simply calls the corresponding @code{Compute_dWt} function on the
@code{ConSpec} for all of the receiving connection groups.  In Bp, it
also calls @code{Compute_dWt} on for the bias weight.
@item UpdateWeights(Unit* u)
@findex UpdateWeights on BpUnitSpec
Updates the weights of the unit's connections based on the
previously computed @code{dEdW}.  Like @code{Compute_dWt}, this function
is defined to call the corresponding one on connection specs.  Also, it
updates the bias weights.  Note that this function is called by the
@b{EpochProcess}, and not by the algorithm-specific @b{BpTrial}
directly.
@end table

The corresponding connection spec functions are as follows.  Note that,
as described in @ref{net-con}, there are two versions of every
function defined in the @b{ConSpec}.  The one with a @code{C_} prefix
operates on an individual @b{Connection}, while the other one
iterates through a group of connections and calls the
connection-specific one.

@table @code
@item float C_Compute_dEdA(BpCon* cn, BpUnit* ru, BpUnit* su)
@findex C_Compute_dEdA on BpConSpec
@item float Compute_dEdA(BpCon_Group* cg, BpUnit* su)
@findex Compute_dEdA on BpConSpec
These accumulate the derivative of the error with respect to the weights
and return that value, which is used by the unit to increment its
corresponding variable.  Note that this is being called on the
@emph{sending} connection groups of a given unit, which is passed as an
argument to the functions.  The computation for each connection is
simply the @code{dEdNet} of the unit that receives from the sending unit
times the weight in between them.
@item float C_Compute_dWt(BpCon* cn, BpUnit* ru, BpUnit* su)
@findex C_Compute_dWt on BpConSpec
@item float Compute_dWt(Con_Group* cg, Unit* ru)
@findex Compute_dWt on BpConSpec
These increment the @code{dEdW} variable on the receiving connections by
multiplying the sending unit's activation value times the receiving
unit's @code{dEdNet}. 
@item float B_Compute_dWt(BpCon* cn, BpUnit* ru)
@findex B_Compute_dWt on BpConSpec
The bias-weight version of this function.  It does not multiply
times the sender's activation value (since there isn't one!).
@item float C_Compute_WtDecay(BpCon* cn, BpUnit* ru, BpUnit* su)
@findex C_Compute_WtDecay on BpConSpec
This calls the weight decay function on the given connection, if it is
not NULL.  It is meant to be called as part of a @code{C_UpdateWeights}
function.
@item float C_BEF_UpdateWeights(BpCon* cn, Unit* ru, Unit* su)
@findex C_BEF_UpdateWeights on BpConSpec
@item float C_AFT_UpdateWeights(BpCon* cn, Unit* ru, Unit* su)
@findex C_AFT_UpdateWeights on BpConSpec
@item float C_NRM_UpdateWeights(BpCon* cn, Unit* ru, Unit* su)
@findex C_NRM_UpdateWeights on BpConSpec
@item float UpdateWeights(Con_Group* cg, Unit* ru)
@findex UpdateWeights on BpConSpec
These are the functions that update the weights based on the accumulated
@code{dEdW}. There is a different version of the connection-specific code
for each of the different @code{momentum_type} values, and the
group-level function has a separate loop for each type, which is more
efficient that checking the type at each connection.
@item float B_UpdateWeights(BpCon* cn, Unit* ru)
@findex B_UpdateWeights on BpConSpec
The bias-weight version of the function, which checks the
@code{momentum_type} variable and calls the appropriate @code{C_}
function.
@end table

The following is a chart describing the flow of processing in the Bp
algorithm, starting with the epoch process, since higher levels do not
interact with the details of particular algorithms:

@example
@group
EpochProcess: @{
  Init: @{
    environment->InitEvents();          // init events (if dynamic)
    event_list.Add() 0 to environment->EventCount(); // get list of events
    if(order == PERMUTE) event_list.Permute();       // permute if necessary
    GetCurEvent();                      // get pointer to current event
  @}
  Loop (trial): @{                      // loop over trials
    BpTrial: @{                         // trial process (one event)
      Init: @{                          // at start of trial
        cur_event = epoch_proc->cur_event; // get cur event from epoch
      @}
      Loop (once): @{                   // only process this once per trial
        network->InitExterns();         // init external inputs to units
        cur_event->ApplyPatterns(network); // apply patterns to network
        Compute_Act(): @{               // compute the activations
          network->layers: @{           // loop over layers
            if(!layer->ext_flag & Unit::EXT) // don't compute net for clamped
              layer->Compute_Net();     // compute net inputs
            layer->Compute_Act();       // compute activations from net in
          @}
        @}
        Compute_dEdA_dEdNet(): @{       // backpropagate error terms
          network->layers (backwards): @{ // loop over layers backwards
            units->Compute_dEdA();   // get error from other units or targets
            units->Compute_dEdNet(); // add my unit error derivative
          @}
        @}
        network->Compute_dWt();         // compute weight changes from error
      @}
    @}
    if(wt_update == ON_LINE or wt_update == SMALL_BATCH and trial.val % batch_n)
      network->UpdateWeights(); // after trial, update weights if necc
    GetCurEvent();              // get next event
  @}
  Final:
    if(wt_update == BATCH)  network->UpdateWeights(); // batch weight updates
@}
@end group
@end example

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  rbp,  , bp-ff, bp
@section Recurrent Backpropagation

Recurrent backpropagation (RBp) extends the basic functionality of
feed-forward backprop to networks with recurrently interconnected units,
which can exhibit interesting dynamical properties as activation
propagates through the network over time.

@menu
* rbp-over::                    Overview of the RBp Implementation
* rbp-con::                     RBp Connection Specifications
* rbp-unit::                    RBp Unit Specifications
* rbp-trial::                   The RBp Trial Process
* rbp-seq::                     RBp Sequence Processes and TimeEvents
* rbp-vari::                    Variations Available in RBp
* rbp-ap::                      The Almeida-Pineda Algorithm in RBp
* rbp-defs::                    RBp Defaults
* rbp-impl::                    RBp Implementation Details
@end menu


@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  rbp-over, rbp-con, rbp, rbp
@subsection Overview of the RBp Implementation
@cindex Recurrent Backpropagation, Implementation

The recurrent backprop implementation (RBp) defines a new set of types
that are derived from the corresponding Bp versions: @b{RBpConSpec,
RBpUnit, RBpUnitSpec, RBpTrial, RBpSequence}.  Note that RBp uses the
same Connection type as Bp.  In addition, support for the Almeida-Pineda
algorithm is made possible by the following set of process types, which
control the activation and backpropagation phases of that algorithm,
which otherwise uses the same basic types as RBp: @b{APBpCycle, 
APBpSettle, APBpTrial, APBpMaxDa_De}.

There are a couple of general features of the version of recurrent
backprop implemented in PDP++ that the user should be aware of.  First
of all, the model used is that of a discrete approximation to a
continuous dynamic system, which is defined by the sigmoidal activation
of the net input to the units.  The granularity of the discrete
approximation is controlled by the @code{dt} parameter, which should be
in the range between 0 and 1, with smaller values corresponding to a
finer, closer to continuous approximation.  Thus, the behavior of the
network should be roughly similar for different @code{dt} values, with
the main effect of @code{dt} being to make updating smoother or rougher.

Also, there are two ways in which the units can settle, one involves
making incremental changes to the activation values of units, and the
other involves making incremental changes to the net inputs.  The latter
is generally preferred since it allows networks with large weights to
update activations quickly compared to activation-based updates, which
have a strict ceiling on the update rate since the maximum activation
value is 1, while the maximum net input value is unbounded.

As in standard backpropagation, recurrent backprop operates in two
phases: activation propagation and error backpropagation.  The
difference in recurrent backprop is that both of these phases extend
over time.  Thus, the network is run for some number of activation
update cycles, during which a record of the activation states is kept by
each unit, and then a backpropagation is performed that goes all the way
back in time through the record of these activation states.  The
backpropagation happens between the receiving units at time t and the
sending units at the previous time step, time t-1.  Another way of
thinking about this process is to unfold the network in time, which
would result in a large network with a new set of layers for each time
step, but with the same set of weights used repeatedly for each time
step unfolding.  Doing this, it is clear that the sending units are in
the previous time step relative to the receiving units.

The exact length of the activation propagation phase and the timing and
frequency of the backpropagation phases can be controlled in different
ways that are appropriate for different kinds of tasks.  In cases where
there is a clearly-defined notion of a set of distinct temporal
sequences, one can propagate activation all the way through each
sequence, and then backpropagate at the end of the sequence.  This is
the default mode of operation for the processes.

There are other kinds of environments where there is no clear boundary
between one sequence and the next.  This is known as "real time" mode,
and it works by periodically performing a backpropagation operation
after some number of activation updates have been performed.  Thus,
there is a notion of a "time window" over which the network will be
sensitive to temporal contingencies through the weight updates driven by
a single backpropagation operation.  In addition, these backpropagations
can occur with a period that is less than the length of the time window,
so that there is some overlap in the events covered by successive
backpropagation operations.  This can enable longer-range temporal
contingencies to be bootstrapped from a series of overlapping 
backpropagations, each with a smaller time window. 

There is a simpler variation of a recurrent backpropagation algorithm
that was invented by Almeida and Pineda, and is named after them.  In
this algorithm, the activation updating phase proceeds iteratively until
the maximum change between the previous and the current activation
values over all units is below some criterion.  Thus, the network
settles into a stable attractor state.  Then, the backpropagation phase
is performed repeatedly until it too settles on a stable set of error
derivative terms (i.e., the maximum difference between the derivative of
the error for each unit and the previously computed such derivative is
below some threshold).  These asymptotic error derivatives are then used
to update the weights.  Note that the backpropagation operates
repeatedly on the asymptotic or stable activation values computed during
the first stage of settling, and not on the trajectory of these
activation states as in the "standard" version of RBp.  The
Almeida-Pineda form of the algorithm is enabled by using the @b{APBp}
processes, which compute the two phases of settling over cycles of
either activation propagation or error backpropagation.

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  rbp-con, rbp-unit, rbp-over, rbp
@subsection RBp Connection Specifications
@cindex Connections, RBp

Since the difference between recurrent backprop and standard
feed-forward backprop is largely a matter of the process-level
orchestration of the different phases, the connection specifications are
identical between the two, with one small difference.  Please refer to
@ref{bp-con} for a description of the relevant parameters.

The exception is only at the level of the equations used to compute the
error derivative terms, which are modified to use the previous
activation value of the sending unit, instead of the current activation,
since the idea is to reduce the error that results at time t as a
function of the activation states that lead up to it, those at time t-1.

Since RBp networks are complex dynamical systems, it is often useful to
place restrictions on the kinds of weights that can develop, in order to
encourage certain kinds of solutions to problems.  One rather direct way
of doing this is by simply limiting the weights to not go above or below
certain values, or to restrict them to be symmetrical.  These can be
accomplished by editing the @b{ConSpec}.


@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  rbp-unit, rbp-trial, rbp-con, rbp
@subsection RBp Unit Specifications
@cindex Units, RBp

The unit-level specifications contain most of the RBp-specific
parameters, although some important ones are also present in the
@b{RBpTrial} process.  Note that the @code{dt} parameter should be the
same for all unit specs used in a given network.  Also, this parameter
is copied automatically to the @b{RBpTrial} process, which also needs to
know the value of this parameter.  Thus, the unit spec is the place to
change @code{dt}, not the trial process.

The unit object in RBp is essentially the same as the @b{BpUnit}, except
for the addition of variables to hold the previous values of all the
state variables, and special circular buffers to hold the entire record
of activation state variables over the update trajectory.  These are
described in greater detail in @ref{rbp-impl}.

@tindex RBpUnitSpec
@table @code
@item float dt
@vindex dt of RBpUnitSpec
Controls the time-grain of activation settling and error
backpropagation as described above.  In @code{ACTIVATION} mode, the
activations are updated towards the raw activation value computed as a
sigmoid function of the current net input by an amount proportional to
@code{dt}:
@example
    u->da = dt * (u->act_raw - u->prv_act);
    u->act = u->prv_act + u->da;
@end example
Similarly, in @code{NET_INPUT} mode, the net-inputs are moved towards
the current raw net input proportional to the size of @code{dt}:
@example
    u->da = dt * (u->net - u->prv_net);
    u->net = u->prv_net + u->da;
@end example
@item TimeAvgType time_avg
@vindex time_avg of RBpUnitSpec
Controls the type of time-averaging to be performed.
@code{ACTIVATION} based time-averaging, as shown above, adapts the
current activations towards the raw activation based on the current net
input, while @code{NET_INPUT} based time-averaging, also shown above,
adapts the net input towards the current raw value.  The latter is
generally preferred since it allows networks with large weights to update
activations quickly compared to activation-based updates, which have a
strict ceiling on the update rate since the maximum activation value is
1, while the maximum net input value is unbounded.
@item bool soft_clamp
@vindex soft_clamp of RBpUnitSpec
Soft clamping refers to the application of an environmental input to the
network as simply an additional term in the unit's net input, as opposed
to a hard-clamped pre-determined activation value.  Soft clamping allows
input units to behave a little more like hidden units, in that raw
inputs are only one source of influence on their activation values.
@item float soft_clamp_gain
@vindex soft_clamp_gain of RBpUnitSpec
A strength multiplier that can be used to set the level of
influence that the inputs have in soft-clamp mode.  This allows the user
to use the same environments for hard and soft clamping, while still
giving the soft-clamp values stronger influence on the net input than
would be the case if only 0-1 values were being contributed by the
external input.
@item bool teacher_force
@vindex teacher_force of RBpUnitSpec
A modification of the RBp algorithm where the activation values are
"forced" to be as given by the teaching (target) values.  Given that the
error is backpropagated over a long series of time steps, this can help
error on previous time steps be computed as if the later time steps were
actually correct, which might help in the bootstrapping of
representations that will be appropriate when the network actually is
performing correctly.
@item bool store_states
@vindex store_states of RBpUnitSpec
This flag determines if activity states are stored over time for use in
performing a backpropagation through them later.  This usually must be
true, except in the Almeida-Pineda algorithm, or when just testing the
network.
@item Random initial_act
@vindex initial_act of RBpUnitSpec
Sets the parameters for the initialization of activation states at
the beginning of a sequence.  This state forms the 0th element of the
sequence of activations.
@end table


@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  rbp-trial, rbp-seq, rbp-unit, rbp
@subsection The RBp Trial Process
@cindex Process, RBp Trial

In order to accommodate both the real-time and discrete sequence-based
processing modes of RBp, the lowest level of processing in RBp is still
the Trial, just as in regular Bp.  Thus, each cycle of activation update
is performed by the trial.  In addition, the trial process looks at the
number of stored activation states that have been accumulated in the
network's units, and if this is equal to the time-window over which
backprop is supposed to occur, the trial process will then perform a
backpropagation through all of these stored activation states.  Thus,
the scheduling of backpropagations is fairly autonomous, which makes
real-time mode work well.  When not operating in real-time mode, the
time-window for error backpropagation is automatically set to be the
total duration of the current sequence.  This makes it easy to use
variable length sequences, etc.

The distinction between whether the network is trained in real-time or
sequence-based mode is based on the kinds of processes that are created
above the level of the @b{RBpTrial} process, and on the setting of the
@code{real_time} flag on the @b{RBpTrial} process itself.  If using the
sequence-based mode, where backpropagations are performed at the end of
discrete sequences of events, then the user should create a
Sequence-based process hierarchy, which includes a @b{SequenceEpoch}, an
@b{RBpSequence} process, and finally a @b{RBpTrial} process.  If one is
using real-time mode, only a regular @b{EpochProcess} and a @b{RBpTrial}
process need to be used.

The following parameters are available on the @b{RBpTrial}.  Note that
all of the parameters are expressed in terms of the abstract time units,
and not in terms of the specific ticks of the discrete clock on which
the actual events are presented to the network, activations are updated,
etc.  This makes the parameters invariant with respect to changes in
@code{dt}, which controls the size of a tick of discrete time.

@tindex RBpTrial
@table @code
@item float time
@vindex time of RBpTrial
The current time, relative to the start of the most recent
sequence, or since the units were last initialized if in real-time mode.
It is a read-only variable.
@item float dt
@vindex dt of RBpTrial
The delta-time increment, which is copied automatically from the
units in the network.  It is used in updating the time in the trial
process.
@item float time_window
@vindex time_window of RBpTrial
Determines the time window over which error
backpropagation will be performed.  Thus, units will hold their
activation states for this long before a backpropagation will occur.
@item float bp_gap
@vindex bp_gap of RBpTrial
The time to wait in between successive backpropagations after
an initial activation settling time of @code{time_window} in duration.
This is used primarily in real-time mode, and controls the amount of
overlap between successive backpropagations.  For example, a
@code{time_window} of 4 and a @code{bp_gap} of 2 would result in the
following schedule of backpropagations:
@example
time:   0 1 2 3 4 5 6 7 8
bp:           x   x   x
@end example
where each backprop goes back 4 time steps, resulting in an overlap of 2
time steps for each backprop.
@item bool real_time
@vindex real_time of RBpTrial
Checking this flag will cause the network to shift the activation
buffers after each backpropagation, so that the appropriate amount of
activation state information will be available for the next
backpropagation (i.e., it shifts them by the size of @code{bp_gap}).  Not
checking this flag will cause the @code{time_window} to be automatically
set to the length of the current sequence.
@end table

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  rbp-seq, rbp-vari, rbp-trial, rbp
@subsection RBp Sequence Processes and TimeEvents
@cindex Process, RBp Sequences
@cindex Sequences, RBp
@cindex Time Environment
@cindex Environment, Time

The @b{RBpSequence} process is a special @b{SequenceProcess} that knows
how to appropriately treat sequences of events that have time values
associated with them.  The classes @b{TimeEnvironment,
TimeEvent_MGroup}, and @b{TimeEvent} together define an environment
which consists of sequences (groups) of events where each event is
specified to occur at a particular time.  Furthermore, the environment
defines certain simple forms of interpolation, which allows trajectories
to be formed by specifying crucial points on the trajectory, but not
everything in between.  Also, the @b{RBpSequence} process uses the
@code{end_time} of the @b{TimeEvent_MGroup} to set the @code{time_window}
of the trial process, so that exactly one backprop phase will happen per
sequence.

If a @b{TimeEnvironment} is not being used, a @b{RBpSequence} will
simply run the sequence of events in each event group, one by one,
through the trial process.  This would make each event in the sequence
appear at tick-wise intervals (i.e., every @code{dt}).  In contrast, the
@b{TimeEnvironment} based events have the benefit of making the
environment invariant with respect to changes in @code{dt}, which can be
very useful when @code{dt} is changed during training, etc.

A @b{TimeEnvironment}, aside from setting the default types of events
and event groups to also be time-based ones, has a default interpolation
parameter:

@tindex TimeEnvironment
@table @code
@item Interpolate interpolate
@vindex interpolate of TimeEnvironment
The following forms of interpolation are defined:
@table @code
@item PUNCTATE
Each event appears for the single slice of time that it has
specified.

@item CONSTANT
Events persist with the same activations from the time on the event
until the next event comes along.

@item LINEAR
Performs linear interpolation from one event to the next.
@end table
@end table

As with all sequence-based environments (@pxref{env-seq}), a sequence of
events is defined by putting all the events in a subgroup.
@b{TimeEvent}s should be put in subgroups of type @b{TimeEvent_MGroup},
which is where the specific form of interpolation to be used for this
particular sequence, and the total duration of the sequence, are
specified:

@tindex TimeEvent_MGroup
@table @code
@item Interpolate interpolate
@vindex interpolate of TimeEvent_MGroup
This is just like the interpolation variable on the environment, except
it includes the @code{USE_ENVIRO} option, which uses whatever is set on
the environment object.  Thus, one can have different sequences use
different kinds of interpolation, or they can defer to the environment.
@item float end_time
@vindex end_time of TimeEvent_MGroup
The total duration of the sequence.  It is automatically set to
be as long as the latest event in the group, but you can set it to be
longer to cause a @code{CONSTANT} interpolation to hold onto the event
until @code{end_time} has been reached.
@end table

@tindex TimeEvent
@vindex time of TimeEvent
The time event object is just like a regular event except that it adds a
time field, which specifies when this event is to first be presented to
the network.  How long it is presented depends on the interpolation
scheme and how soon another event follows it.

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  rbp-vari, rbp-ap, rbp-seq, rbp
@subsection Variations Available in RBp

@tindex NoisyRBpUnitSpec
@vindex noise of NoisyRBpUnitSpec
@b{NoisyRBpUnitSpec} adds noise into the activation states of the RBp
unit.  The type and parameters of the noise are defined by the
@code{noise} settings.


@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  rbp-ap, rbp-defs, rbp-vari, rbp
@subsection The Almeida-Pineda Algorithm in RBp
@cindex Almeida-Pineda Algorithm
@tindex APBpTrial
@tindex APBpCycle
@tindex APBpSettle
@tindex APBpMaxDa_De

The Almeida-Pineda backprop (APBp) algorithm is a lot like the recurrent
backpropagation algorithm just described, except that instead of
recording the activation trajectory over time, and the backpropagating
back through it, this algorithm performs activation propagation until
the change in activation goes below some threshold, and then it performs
backpropagation repeatedly until the change in error derivatives also
goes below threshold.

This algorithm is implemented by using the standard RBp unit and
connection types, even though APBp doesn't require the activation trace
that is kept by these units.  Indeed, you should set the
@code{store_states} flag on the @b{RBpUnitSpec} to @code{false} when
using APBp.

The only thing that is needed is a set of processes to implement the
settling process over cycles of activation and error propagation.  Thus,
three new processes were implemented, including a cycle process
(@pxref{proc-levels-cycle}) to perform one cycle of activation or error
propagation, a settle process (@pxref{proc-levels-settle}) to iterate
over cycles, and a train process (@pxref{proc-levels-train}) to iterate
over two phases of settling (activation and backpropagation).

The @b{APBpCycle} and @b{APBpSettle} processes don't have any
user-settable parameters.  The @b{APBpTrial} adds a couple of options to
control settling:

@tindex APBpTrial
@table @code
@item Counter phase_no
@vindex phase_no of APBpTrial
The counter that controls what phase the process is in.
@item Phase phase
@vindex phase of APBpTrial
The phase, which is either @code{ACT_PHASE} or @code{BP_PHASE}.
It is essentially just a more readable version of the phase_no counter.
@item StateInit trial_init
@vindex trial_init of APBpTrial
Determines what to do at the start of settling.  One can either
@code{DO_NOTHING} or @code{INIT_STATE}, which initializes the unit
activation state variables, and is the default thing to do.
@item bool no_bp_stats
@vindex no_bp_stats of APBpTrial
This flag, if set, does not collect any statistics during the Bp phase
of settling.
@item bool no_bp_test
@vindex no_bp_test of APBpTrial
This flag, if set, means that no backpropagation settling phase will be
computed if the epoch process is in @code{TEST} @code{wt_update} mode.
@end table

The threshold that determines when the settling is cut off is determined
by a @b{APBpMaxDa_De} statistic object, which measures the maximum
change in activation or the maximum change in error derivative.  The
stopping criterion (@pxref{proc-stat-crit}) of this stat determines the
cutoff threshold.  It assumes that the same threshold is used for
activation as is used for error, which seems to be reasonable in
practice.

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  rbp-defs, rbp-impl, rbp-ap, rbp
@subsection RBp Defaults
@cindex Defaults, RBp
@cindex RBp, Defaults

The following default files (@pxref{proj-defaults}) are available for
configuring different versions of the RBp objects:

@table @file
@item rbp.def
This is the standard defaults file.
@item rbp_ap.def
This is for doing Almeida-Pineda (@pxref{rbp-ap}) in RBp.
@end table

@c ======================================
@c    <node>, <next>, <prev>, <up>
@node  rbp-impl,  , rbp-defs, rbp
@subsection RBp Implementation Details

An attempt was made to make the implementation of RBp very flexible,
modular, and robust.  Thus, units keep track of their own sense of time
and record their own history of activations.  This is done with a
@b{CircBuffer} object, which is derived from an @b{Array} type
(@pxref{obj-array}).  Values in this buffer can wrap-around, and can be
shifted without performing any memory copying.  Thus, the unit
activation records can be quickly shifted after performing a
backpropagation enough to make room for new states to be recorded.  The
trial process will shift the buffers just enough so that they will be
full again the next time a backpropagation will occur (i.e., they are
shifted by the @code{bp_gap} value converted into tick units).

However, the buffers are robust in the sense that if the bp_gap
parameter is changed during processing, they will simply add new states
and dynamically increase the size of the buffer if it is already full.
Indeed, when a unit first starts processing, the buffer is automatically
added to by the same mechanism--it is always full until some number of
values have been shifted off the end.

The units only record their activation values in the buffers.  Thus,
there is a @code{StoreState} function which takes a snapshot of the
current activation state.  It is called at the end of the
@code{Compute_Act} function.  During backpropagation, the
@code{StepBack} function is called, which will take one step back in
time.  The activation state recorded in the @code{prv_} version of the
unit variables are copied into the current variables, and the new
previous values are loaded from the buffers at the given tick.

The backpropagation loop looks as follows:

@example
@group
PerformBP(): @{
  InitForBP();                  // clear current and prev error vals
  int buf_sz = GetUnitBufSize(); // get unit buffer size (states in units)
  for(i=buf_sz-2; i>=0; i--) @{ // loop backwards through unit states
    Compute_dEdA_dEdNet();      // backpropagate based on current state
    Compute_dWt();              // compute weight changes from error
    if(i > 0)                   // if not all the way back yet
      StepBack(i-1);		// step back to previous time
  @}
  RestoreState(buf_sz-1);	// restore activations to end values
  if(real_time)
    ShiftBuffers();		// don't shift unless real time
@}
@end group
@end example

Thus, error derivatives are computed on the current and @code{prv_}
activation state variables, and then these are shifted backwards one
step, and this continues for the entire length of stored activation
values.  The above routine is called by the trial process whenever the
buffer size of the units is equal to or greater than the bp time window.

During backpropagation, the @code{prv_dEdA} and @code{prv_dEdNet} values
are kept, and are used to time-average the computations of these values,
much in the same way the activations or net inputs are time averaged
during the activation computation phase.

The following is a chart describing the flow of processing in the RBp
algorithm, starting with the epoch process, since higher levels do not
interact with the details of particular algorithms, and assuming
sequences are being used:

@example
@group
SequenceEpoch: @{
  Init: @{                              // at start of epoch
    environment->InitEvents();          // init events (if dynamic)
    event_list.Add() 0 to environment->GroupCount(); // get list of groups
    if(order == PERMUTE) event_list.Permute(); // permute list if necessary
    GetCurEvent();                      // get pointer to current group
  @}
  Loop (trial): @{                      // loop over trials
    SequenceProcess: @{                 // sequence process (one sequence)
      Init: @{                          // at start of sequence
        tick.max = cur_event_gp->EventCount(); // set max no of ticks
        event_list.Add() 0 to tick.max; // get list of events from group
        if(order == PERMUTE) event_list.Permute(); // permute if necessary
        GetCurEvent();                  // get pointer to current event
        InitNetState() @{               // initialize net state at start
          if(sequence_init == INIT_STATE) network->InitState();
        @}
      @}
      Loop (tick): @{                   // loop over ticks (sequence events)
        RBpTrial: @{                    // trial process (one event)
          Init: @{                      // at start of trial
            cur_event = epoch_proc->cur_event; // get event from sequence
          @}
          Loop (once): @{               // process this once per trial
            network->InitExterns();     // init external input to units
            cur_event->ApplyPatterns(network); // apply patterns from event 
            if(unit buffer size == 0) @{ // units were just reset, time starting
              time = 0;                 // reset time
              StoreState();             // store initial state at t = 0
            @}
            Compute_Act(): @{           // compute acts (synchronous)
              network->Compute_Net();   // first get net inputs
              network->Compute_Act();   // then update acts based on nets
            @}
            if(unit buffer size > time_win_ticks) // if act state buffers full
              PerformBP();              // backpropagate through states
            time += dt;                 // time has advanced..
          @}
        @}
        if(wt_update == ON_LINE) network->UpdateWeights(); // after trial
      @}
    @}
    if(wt_update == SMALL_BATCH)        // end of sequence
      network->UpdateWeights();         // update weights after sequence
    GetCurEvent();                      // get next event group
  @}
  Final:                                // at end of epoch
    if(wt_update == BATCH)  network->UpdateWeights(); // batch mode updt
@}
@end group
@end example

